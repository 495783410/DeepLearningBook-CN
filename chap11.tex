%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%author:rickymf4%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{实战方法}
\label{chap:11}

成功地应用深度学习技术远远不仅仅需要知道有哪些算法和这些算法的原理。一个好的机器学习实践者亦需要知道如何针对特定的应用选择算法，如何监控实验并对获得的反馈做出回应，从而优化该机器学习系统。在机器学习系统的日常开发中，实践者们需要决定是否需要搜集更多的数据，是增加还是减少模型的容量，是加上还是去掉规则化特征，是改进模型的优化，还是改进模型中的近似推理，亦或是对模型的实现程序进行调试。所有这些操作都是非常耗时的尝试，所以能够确定正确的行动方针是很重要的，而不是盲目猜测它。

这本书的大部分内容是关于各种机器学习模型、训练算法，和目标函数。这可能会造成这样的印象：成为机器学习专家最重要的本领是要了解各种机器学习技术并擅长不同类型的数学。 然而在实践中，正确地使用一个常见的算法比草率地使用一个晦涩的算法要好。算法的正确应用取决于掌握一些相当简单的方法。本章节中许多建议改编自\cite{Ng ( 2015 )}.

我们建议如下的实际设计过程：
\begin{itemize}
\item 确定您的目标 - 要使用的误度量和相应的目标价值。这些目标和误差度量应该由应用要解决的问题来驱动。
\item 尽快建立一个可以工作的端到端的流水线，包括适当估计它的性能指标。
\item 较好地给系统装上仪表来确定其性能瓶颈。诊断哪些组件的性能低于预期，以及是否是由于过度拟合、欠拟合，或数据或程序中存在着缺陷。
\item 基于来自仪表中特定的发现，重复地进行增量变更，如收集新数据，调整超参或更改算法。
\end{itemize}

我们将采用街景地址号码翻译系统作为一个运行的例子 (\cite{ Goodfellow et al. , 2014d })。 这个应用的目的是将建筑添加到谷歌地图中。街景车对建筑进行拍摄并记录照片对应的GPS坐标。通过卷积网络来识别每张照片中的地址号码，使得谷歌地图数据库可以将该地址加入到正确的位置上。关于如何开发这个商业应用程序的故事给出了如何遵循我们倡导的设计方法的例子。我们现在来描述这个过程中的每个步骤。

\section{性能指标}

确定目标（根据将采用的错误率指标）是必要的第一步，因为你的错误率指标将指导你以后的所有操作。你还应该知道你想要什么级别的性能。

请记住，对于大多数应用，不可能实现绝对零错误率。即使你有无限训练数据，并且可以恢复真实的概率分布，而贝叶斯误差定义了你可以希望实现的最小错误率。这是因为你的输入特征可能不包含有关输出变量的完整信息，或者因为系统可能是内在随机的。你也将受限于有限数量的训练数据。

由于各种原因，训练数据的量被限制了。当你的目标是构建一个一流的实际的产品或服务时，您通常可以收集更多数据，但必须确定进一步减少错误率的价值，并将其与收集更多数据的成本进行权衡。数据收集可能需要时间、金钱或使人遭受痛苦（例如，如果您的数据收集过程涉及侵入性的医学测试）。 而当你的目标是回答在固定的基准上哪个算法的表现更好时，通常是不允许收集更多数据作为基准的训练集的。

如何给性能水平确定一个合理的期望？通常，在做学术时，我们基于以前发布的基准测试结果，可以做一些错误率的估计。而在做实际项目时，我们考虑的错误率是要让我们的应用是安全的，成本效益的，或是吸引消费者的。一旦确定了实际期望的错误率，那么为了达到此错误率将指导你的设计决策。

除了性能指标的目标值之外的另一个重要考虑是选择使用哪个指标。可以使用几种不同的性能指标来测量一个完整的包含各种机器学习组件的应用的有效性。这些性能指标通常不同于用于训练模型的代价函数。 如第5.1.2节所述，我们通常测量系统的准确率或错误率。

然而，许多应用需要更高级的指标。

有时一种错误的代价会比另一种更高。例如，电子邮件垃圾检测系统可能产生两种错误：错误地将合法的邮件分类为垃圾邮件，以及错误地允许垃圾邮件在收件箱中显示。

阻止合法消息比允许可疑消息通过更糟糕。 我们不是测量垃圾邮件分类器的错误率，我们可能希望用某种形式来衡量总体代价，认为阻止合法邮件的代价高于允许垃圾邮件。

有时我们想要训练一个二元分类器，用于检测一些异常事件。例如，我们将要为一个罕见的疾病设计一个医学测试。假设每百万人中只有一人患有这种疾病。我们通过简单地将分类器结果固定为无疾病，可以很容易地实现99.9999％的检测精度。显然，用准确性来表征这种系统的性能的是不行的。 解决这个问题的一种方法是改为采用精度和召回(ure precision and recall)的统计方法。精度是模型的检测结果中正确的比例，而召回是真实事件被模型检测到的比例。当一个检测器说没有人患这种疾病时将有完美的精度，但召回是零。当一个检测器说每个人都有疾病时将实现完全召回，但精度等于患有该疾病的人的百分比（在我们的例子中，一百万人中有一人的比例是0.0001％）。当使用精度和召回时，我们通常绘制PR曲线，y轴表示精度，x轴上表示召回。当待检测的事件发生时，分类器将输出较高的分数。 例如，一个检测疾病的前馈网络的输出y = P（y = 1 | x），表示医疗结果具有特征x的人的患病概率。当该输出概率分数大于某个阈值时，则认为检测到了。通过改变阈值，我们可以权衡在某召回下的精度。在许多情况下，我们希望用单个数字而不是曲线来总结分类器的性能。为此，我们将精度p和召回r转换为一个F分数，如公式11.1所示：
F = 2pr / (p + r) (11.1)

另一个方法是统计位于PR曲线下方的总面积。

在一些应用中，机器学习系统可以拒绝做决定。当机器学习算法可以估计一个决策的可信度时这是有用的，特别是如果错误的决策可能带来危害并且操作人员能够偶尔接管的话。街景翻译系统就是这样一个例子。 它的任务是从照片中翻译地址号码，以便将拍摄照片的位置与地图中的正确地址相关联。因为如果地图不准确，地图的价值会大大降低，所以只有在翻译正确的情况下才添加地址非常重要。如果机器学习系统比人类更难获得正确的翻译，那么最好的办法就是让人来替代。当然，如果机器学习系统能够大大减少运营人员必须处理的照片数量，那么它是有用的。在这种情况下使用覆盖率来作为性能指标。覆盖率是机器学习系统能产生响应的样本的比率。 可以将覆盖率和准确率进行权衡。 如果我们决绝了所有样本，则能获得100\%的准确率，但覆盖率减少到0\%。对于街景翻译这个任务，目标是在保持95\%的覆盖率下达到人类水平的翻译准确率。在这个任务上，人类水平为98\%。

还有可能是其它指标。 例如，我们可以衡量点击率，收集用户满意度调查等。许多专业应用领域也有应用特定的标准。

重要的是确定要先提高哪个性能指标，然后集中精力提高这个指标。没有明确的目标，很难判断机器学习系统的优化是否取得进展。


\section{默认基准模型}

选择性能指标和目标后，下一步，对于任何的实际应用都是要尽快建立一个合理的端到端系统。 在本节中，我们提供了在各种情况下用哪个算法作为第一个基准方法建议。 请记住，深度学习研究是进展很快的，所以更好的默认算法可能在写完后很快就能用。

根据你的问题的复杂性，你甚至可能不想使用深度学习。如果你的问题可以通过正确地选择一些线性权重就能解决，你可能从一个简单统计模型开始做，如逻辑回归。

如果你知道你的问题属于“AI-完全的”类别，如物体识别，语音识别，机器翻译等等，那么你很可能通过一个恰当的深度学习模型来做出比较好的效果。

首先，根据你的数据的结构，选择一个类型的模型。如果你想做有监督学习，而且有固定大小的向量作为输入，那么使用带全连接层的前馈网络。如果已知输入的拓扑结构（例如，输入是一幅图像），那么使用卷积网络。在这些情况下，你应该从使用一些分段线性单元（ReLUs 或其推广如Leaky ReLUs，PreLus和MAXOUT）开始。如果你的输入或输出是一个序列，那么使用门控递归神经网络（LSTM或GRU）。

优化算法的合理选择是带动量的随机梯度下降法(SGD)，加上带衰减的学习率（流行的衰减方法在不同的问题上表现有好有坏，包括：线性地衰减到一个固定的最小值，指数衰减，或每次遇到验证错误率趋于平稳时将学习效率降低2到10倍）。另一个非常合理的选择是Adam方法。批量归一化对优化性能有很大的影响，尤其是卷积网络和带sigmoidal 的非线性的网络。虽然你刚开始的第一个基线不用批量归一化是合理的，但如果优化似乎是有问题的，应该马上使用它。

除非你的训练集包含了数千万的例子或更多，否则你应该从开始就引入一些轻度的正规化。及早停止普遍被使用。Dropout是一种不错的正则化方法，它易于实现，并与许多模型和训练算法兼容。批量归一化也往往能降低泛化误差，而不用dropout，这是因为在用于规范化每个变量的统计估计中存在噪声。 

如果你的任务和另一个被广泛研究的任务相似的话，你可以先拷贝那些已经被证明在先前研究任务上表现最好的模型和算法，从而获得比较好的结果。您甚至可以从该任务复制一个训练好的模型。例如，一个是常见的做法是使用基于在ImageNet上训练得到的卷积网络的特征，来解决其他计算机视觉任务（Girshick，2015）。

一个常见的问题是，是否要使用无监督学习，我们会在第三部分进一步介绍。这是和一些特定领域的有关的。有一些领域，如自然语言处理，都大大受益于无监督学习技术，如学习无监督词嵌入。在其他领域，如计算机视觉，目前的无监督学习技术没有优势，除了基于少量标记样本的半监督的学习（金马等人，2014；Rasmus et al.，2015）。如果无监督学习对你的应用重要时，那么你可以引入它作为你第一个端到端学习的基线。否则，只有当你想解决的任务是无监督的时候，你才用无监督学习。还有，如果你发现你的初始基线过拟合了，你总是可以在后期尝试引入无监督学习。


\section{确定是否收集更多的数据}

在建立了第一个端到端的系统之后，接下来便是测量我们的算法性能，并确定如何改进它。 许多机器学习新手试图通过尝试许多不同的算法来进行改进。 然而，收集更多的数据往往要比改进学习算法更有效。

如何决定是否收集更多的数据？ 首先，确定在训练集上的性能是否是可接受的。 如果在训练集上的性能差，那么学习算法并没有利用已有的训练数据，因此没有理由收集更多数据。 相反，得尝试通过添加更多的层或向每个层中添加更多隐藏单元来增加模型的大小。 此外，还得尝试改进学习算法，例如通过调整学习率等超参。如果你用的是大模型，并且对其进行了精心的调整优化，却不能很好地工作，则可能是训练数据质量的问题。 数据可能含有太多噪声，或可能不包括待预测的目标输出的所需的正确输入。这时建议你从头开始，收集更干净的数据或收集更丰富的特征集合。

如果在训练集上的性能可接受，那么对测试集上的性能进行测试。如果测试集上的性能也是可接受的，那么没有什么可以做的了。如果测试集上的性能比训练集上的性能糟糕得多，那么最有效的解决方案之一便是收集更多的数据。要考虑的关键因素是收集更多数据的成本和可行性，通过其他方式降低测试集错误率的成本和可行性，以及预期能显着提高测试集性能的所需的数据量。在拥有数百万或数十亿用户的大型互联网公司，收集大型数据集是可行的，这样做的费用可能远低于其他替代方案，因此答案几乎总是收集更多的训练数据。例如，构建大规模的标记数据集是解决目标识别的最重要的因素之一。而在其他情况下，例如医疗应用，收集更多数据可能是昂贵的或不可行的。一个简单的替代收集更多数据的方法是通过调整超参（例如权重衰减系数）或通过添加正则化策略（例如dropout）来减小模型的大小或改进正则化。如果您发现即使调整正则化超参后，训练和测试性能之间的差距仍然不可接受，那么建议你收集更多的数据。

在决定要收集更多数据时，还需要决定收集多少。我们可以绘制训练集大小和泛化误差之间的关系曲线，如图5.4所示。 通过外推这样曲线，可以预测要达到某个性能水平所需要的额外训练数据量。通常，添加相对总量很小的一部分样本数量不会对泛化错误产生显着影响。 因此建议你以对数标量来设置训练集的大小进行实验，例如使相邻两次实验之间的数据量加倍。

如果收集更多的数据是不可行的，唯一一个其它的方法来改进泛化误差是改进学习算法本身。这变成是一个研究领域，而不是单单给应用实践者一些建议的范畴。

