\chapter{机器学习基础}
\label{chap:5}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% author:dormir_yin %%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

深度学习其实也是机器学习的一种方法。为了更好的理解深度学习，我们必须也要了解一下机器学习的基础知识。这章给大家简要介绍了机器学习中一些重要的概念，这些内容在本书的后续章节会涉及到。如果你是初学者或者想对机器学习有更广更详细的了解，推荐你找一本机器学习的教科书。比如说Murphy(2012)或者Bishop(2006)。如果你已经对机器学习的基础比较熟悉了，你可以直接开始看5.11。那部分内容介绍的传统机器学习技巧对深度学习算法的发展有较大的影响。

我们首先会先定义一下什么是机器学习算法。随后我们会给一个例子 线性回归算法。接着我们介绍拟合训练数据和将我们学习到的模型运用到新的数据集的不同之处。大部分机器学习算法会让我们设置超参数。这些超参数是需要我们自己定义的，而不能通过训练过程自动更新。我们也会讨论如何设置超参数。机器学习本质上就是应用统计学。和应用统计学不同的是它强调了了利用计算机来对一些复杂的函数进行统计估计。但是减弱了对估计出来的函数计算置信区间。就是说它利用统计学方法的得出一个模型，但它不强调用传统的假设检验的方式来对该模型进行评估。接着我们会介绍两个核心的统计算法 频率估计 和 贝叶斯推断。频率学派和贝叶斯学派也是统计学的两大流派。大部分机器学习任务可以分为监督学习和无监督学习两类。我们会对这两类做一个介绍，同时会介绍一些它们用到的机器学习算法。大部分深度学习算法是基于一种叫随机梯度下降法的优化算法。我们会介绍如何构建一个完整的机器学习算法。这些算法包含多个部分。优化算法，损失函数，模型和数据集。最后，在\ref{sec:5.11}我们介绍了传统机器学习算法遇到的一些困难，这些困难促使我们发展深度学习来解决传统机器学习算法所不能解决或者很难解决的问题。

\section{机器学习算法}
\label{sec:5.1}

所谓机器学习算法，就是能够从数据中学习的算法。但是学习到底是什么含义。Mitchell 提供了一个定义。一个计算机程序从关于不同类型的任务的经验中进行学习。

我们可以想象，经验 任务 还有评估策略可以有很多，在这本书中不会给这些名词一个正式的定义。但是我们在接下来的章节中会对他们进行大致的描述，并给一些例子来帮助大家这些名词，已经如何用它们来组成一个机器学习算法。

\subsection{任务 $T$}
机器学习可以解决一些传统的算法很难解决的问题，之前我们总会用人为设计的固定的算法来解决一些问题。从一个科学或者哲学的观点来看，机器学习之所以有趣，是因为在发展理解机器学习算法的同时，我们也会思考发现人类智能的本质。人是如何思考的。

在这一段，我们会给任务 T 一个相对正式的定义。学习本身的过程不能称之为任务，学习的目的是为了获得完成任务的能力。举个例子: 如果我们制作出了一个机器人，想让它具有走路能力，那么走路就是任务T。我们可以写一个程序让机器人自己学习如何走路，也可以直接写一个程序直接控制机器人走路。

机器学习任务通常机器学习系统如何处理一个个实例 Example。实例是特征的集合。这些特征来自于我们设计的机器学习系统需要处理的事件或者物体，而且都已经被量化了。我们通常把实例表示成一个向量，向量的每个元素表示不同的特征。比如说图像的特征通常就是图像的像素值。

机器学习可以解决很多不同的任务。下面我列举了最常见的机器学习任务:
\begin{itemize}
\item \textbf{分类：} 在这类任务中，总共有k类，计算机算法需要判断每个输入属于哪个类别。为了完成这个任务，学习算法通常需要产生一个函数，或者叫对应关系。模型会将每个输入x对应到某个类别y。当然也有很多类似的分类任务，比如说f输出一个概率分布，每个类别对应一个概率。物体识别就是分类任务的一个例子。这个任务重输入时一幅图片 通常可以描述成像素值的集合。输出是图片中物体对应的编码。比如说机器人 就可以识别不同的饮料，并把他们送给点单的客人。深度学习在完成目标检测都有较好的效果。同时，目标检测的算法也可以用于人脸识别，这样我们就可以对照片里的每个人进行自动标注了，而且也可以帮助计算机更好的和人类进行交互。

\item \textbf{缺失特征情况下的分类：} 如果一些数据缺失某些特征的化，分类问题会变得比较难。也就是说不能保证输入向量里每个对应的特征都可以提供。不同的x缺德特征也有可能不一样。传统的分类任务中，学习算法需要定义一个函数，能够将输入向量映射到一个输出类别。但如果一些输入特征缺失了，学习算法就需要定义一系列函数，

\item \textbf{回归：}  在这类任务重，计算机程序需要根据输入预测一下数值。为了解决这个问题，学习算法需要得到一个函数 这类人物和分类任务很像，唯一的不同就是输出的格式不一样，分类任务要求输出的是输入对应的类别，是离散的，而回归任务要求的输出是连续的数值。

\item \textbf{描述：}  在这类任务中，机器学习系统需要观察一些非结构化数据，然后用文字或者离散化的符号描述它们。比如说文字识别，计算机程序需要识别出图片中所包含的文字，然后将识别出来的文字返回。谷歌的 就是利用深度学习来街道号码的。另一个例子是语音识别，计算机程序会根据输入的波形来判断我们说的话。然后将它们转成文字或者文字对应的编码。现在深度学习是语音识别系统一个非常重要的组成部分，已经被好多大公司使用，包括微软，IBM，谷歌。

\item \textbf{机器翻译：}  在机器翻译任务中，我们需要将某种语言的序列翻译成另一种语言的对应的序列。这是自然语言处理的的一部分，比如说将音乐翻译成法语。深度学习在这些任务中，表现的越来越出色。
\item \textbf{结构化输出：} 这类任务一般都要求输出是一个向量，或者其他能够存储多个值的数据结构。这样的任务太多了，包括我们上面提到的描述和机器翻译。当然还有一些其他的任务，比如说将

\item \textbf{异常检测：}  在这类任务中，计算机程序会对输入的事件和目标进行筛选，找出那些异常的的事件或者事物。信用卡欺诈检测就是这类任务的一个例子。通过对你的消费习惯进行建模，当你的卡被盗刷的时候，信用卡公司可以检测出来这个异常事件。当小偷盗取了你的行用卡或者信用卡信息，他进行消费的时候，这些消费记录会和你的消费习惯的概率分布不一致。这样信用卡公司在检测到你的信用卡账号有异常购买记录的时候就会直接把你的信用卡给锁了。可以看一下，里面介绍了一些异常检测的方法。

\item \textbf{模仿合成及采样：}  在这类任务中，机器学习算法或生成一些和训练数据相似的数据。这类任务在艺术和多媒体领域很有用，艺术家进行创造的过程是很枯燥的，而且要花费大量的经历。比如说，在电脑游戏中，我们可以自动生成一些物品和风景。而不是依靠艺术家一点一点画出来。当然我们也可以接收一些比较特殊的输入。比如说语音合成，我们输入一个句子，然后程序就会合成这个句子对应的语音波形。这也是上文提到的结构化输出任务，但是在这个任务中每个输入并没有对应的唯一的正确的输出。我们期望输出会有多一点的变化，这样就会让人感觉更加自然和真实。

\item \textbf{缺失值预测：} 在这类任务中，机器学习算法我们会输入给机器学习算法一个数据实例，但是它的某些元素是缺失的。这个算法必须对这些缺失值作出预测。

\item \textbf{去噪：} 在这类任务中，我们会给学习器一个被污染的数据，这个被污染的数据是原始的纯净数据经过一个未知的污染过程所得到的。学习器必须从这个被污染的数据中预测出原始的那个纯净的数据。或者说，预测出条件概率分布。

\item \textbf{密度估计和概率质量函数估计：} 在密度估计的问题中，机器学习算法需要学习一个函数。x从某个概率分布空间采样出来的数据。当x是连续变量的时候， 可以被看做是密度函数。当x是离散的时候，这个可以被看成一个概率质量函数。为了完美的完成这个任务 当然如何评价模型的好坏我们会在下面一个小结来讨论。这个算法需要我们学习数据的分布，我们需要知道哪些地方出现的数据多，哪些范围数据很少出现。这些任务需要学习算法可以得到数据分布的信息。我们可以通过对这些分布信息进行计算处理来完成其他任务。比如说我们通过概率估计获得了概率分布px，我们可以使用这个结果来解决上面提到的缺失值预测任务。如果缺失了，但是我们有其他的值。这样我们就知道缺失值得条件概率分布式 。在实际应用中，密度分布估计不能总是帮助我们解决这些相关的问题。因为很多情况我们需要通过px来做的一些计算是很难的。
\end{itemize}

当然，还有很多其他类型的任务。我们在这列了这么多只是想告诉大家机器学习能做的一些例子。这些并不是一个严格的任务的分类。


\subsection{评估准则 $P$}
为了能够对机器学习算法进行评估，我们需要针对模型的表现设计一些可以量化的评价准则。通常针对不同的任务我们会设计不同的评价准则。
对于分类任务，有缺失值得分类任务，识别任务我们使用精度来评价模型。精度就是那些模型给出正确输出的数据所占的比例。我们也可以通过计算错误率来获得同样的信息。错误率和模型相反，是模型给出错误输出的数据所占的比重。这个错误率也可以看做是01损失。在某个特定的数据例子上，如果被正确分类了，那么损失是0，否则损失是1. 但是对于概率密度估计这类任务，估计精度就，错误率或者其他类似01损失就没有意义。我们需要找一个新的评估准则来对每个数据点一个分数，这个分数的取值范围是连续的。最常用的方法就是通过模型来给每个数据点赋予一个平均对数概率。
通常我们比较重视模型的泛化性，也就是说看这个模型在处理它之前没见过的数据上面的表现。这个表现可以看出它在实际使用中是否可以工作的很好。因此，我们会通过一个测试集来评估模型，这个测试集是从我们之前用于训练模型的数据集里面分离出来的。
我们的评估准则可能看上去很直接。但是我们其实很难给系统选择一个评估准则可以真正符合我们的要求。
在一些情况下，我们很难决定我们需要评估什么。举个例子，在描述任务中，我们评估精度的时候，我们应该考虑整个序列，当整个序列都正确我们才算对，还是使用一个更细致的评估准则，当序列中某一部分对的时候，我们也给一点分，而不是直接给零分。在回归任务中，对于两个系统，一个会经常发生一些小错误，一个偶尔会发生一些大错误。我们会更偏向哪个呢，或者说准备给那个系统一个更大的惩罚。我们要根据我们的实际需求来作出选择。
在其他一些情况下，我们可以明确需要评估的对象。但是评估的过程不是很方便。举个例子，在概率密度估计的任务中经常会遇到这些问题。很多最好的概率模型表示的概率分布是暗含的，如果你想计算空间中某个特定点的概率值在这些模型中是不可以的。在这种情况下我们需要重新设计一些规则，使我们目标。或者设计一个和理想规则的近似规则。



\subsection{经验 $E$}
根据在学习过程中可以允许获得的经验的类型，机器学习算法可以直接分成监督学习和无监督学习。

这本书介绍的大多数机器学习算法可以被理解成能够接触整个数据集。在511 ，我们已经定义了一个数据集就是很多数据实例的集合。数据实例我们有时候也叫他数据点。

鸢尾花数据集就是一个相当古老的数据集，很早就被统计学家和机器学习研究者来使用。这个数据集记录了鸢尾花不同部分的数据。总共记录了150株鸢尾花，每一株就是一个数据实例。数据实例里面的特征对应的就是鸢尾花不同的部分。萼片长度，萼片宽度，花瓣长度，花瓣宽度。数据集还记录了每个鸢尾花对应的类别。总共有3种不同的鸢尾花类别。

无监督学习算法会遍历整个数据集，一般这个数据集包含很多特征。算法会从数据集的结构中学习其中有用的属性。在深度学习中，我们通常想学习产生数据集的概率分布。判断这个目标函数是不是很直接，类似于概率密度估计。或者是类似于合成，去噪之类的任务。目标不是很明显。还有一些其他的无监督学习算法，比如说聚类，就是根据数据实例的相似度将数据集分成几类。

监督学习算法的数据集也有很多特征，但是每个数据实例都会对应一个标签。比如说鸢尾花集里的每个数据实例就对应某种鸢尾花的类别。一个监督学习算法可以学习整个鸢尾花集，随后就可以将新的数据分成三种不同的鸢尾花类别。

简单的来说，无监督学习会观察几个实例$x$，这几个实例一般都是随机向量。并且会从这些数据集中来学习概率分布$p(x)$，或者这个分布中其它的一些性质。在监督学习里，也会观察一些实例x，但是，每个实例都有一个对应的值或者向量。我们需要通过通过$x$来预测$y$。通常我们会使用$p(y,x)$来进行估计。我们之所以叫监督学习是因为我们会提供一个目标值$y$。就好像是有一个老师来教机器学习系统该如何去做。在无监督学习中，并没有什么老师，机器学习算法需要独自理解数据的内容，或者从中发现一些有趣的东西。
监督学习和非监督学习并没有一个正式的定义。它们之间的界限也比较模糊。很多机器学习算法既可以做监督学习任务，也可以做非监督学习任务。举个例子，在概率图中有一个链式法则：给定一个向量$x$，它的联合分布可以被分解成：

表面上看求联合概率密度是一个非监督学习任务，但是通过这个分解我们把求联合概率px的任务分解成了n个监督学习的问题。相反，当我们想解决监督学习问题$p$ 我们可以通过传统的无监督学习的的技术来学习$x$,$y$的联合分布然后我们就可以用贝叶斯公式来解决这个问题：
